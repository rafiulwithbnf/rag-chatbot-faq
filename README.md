# ğŸ§  Local RAG Chatbot

A lightweight **Retrieval-Augmented Generation (RAG)** chatbot that runs entirely on my local machine.  
It uses **FAISS** for semantic search, **sentence-transformers** for embeddings, and **Ollama** (LLaMA 3B) for natural language generation.



## ğŸš€ Features
- ğŸ  **Local-first**: No external API calls â€” everything runs on your machine.
- ğŸ” **Semantic Search**: Finds the most relevant text chunks from your docs.
- ğŸ§© **Chunking Strategy**: Q&A-aware chunking for better context.
- ğŸ¤– **LLM-Powered Answers**: Context-aware responses generated by Ollama.



## ğŸ› ï¸ Tech Stack
- **Python 3.11+**
- **FAISS** (vector database)
- **sentence-transformers** (`all-MiniLM-L6-v2`)
- **Ollama** (`llama3.2:3b`)



## ğŸ“Š System Workflow


**Plain English:**  
1. **User asks a question**  
2. **Retriever** finds the most relevant chunks from the knowledge base  
3. **Generator (LLM)** uses those chunks to produce an accurate, grounded answer  
