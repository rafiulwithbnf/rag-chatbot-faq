# 🧠 Local RAG Chatbot

A lightweight **Retrieval-Augmented Generation (RAG)** chatbot that runs entirely on my local machine.  
It uses **FAISS** for semantic search, **sentence-transformers** for embeddings, and **Ollama** (LLaMA 3B) for natural language generation.



## 🚀 Features
- 🏠 **Local-first**: No external API calls — everything runs on your machine.
- 🔍 **Semantic Search**: Finds the most relevant text chunks from your docs.
- 🧩 **Chunking Strategy**: Q&A-aware chunking for better context.
- 🤖 **LLM-Powered Answers**: Context-aware responses generated by Ollama.



## 🛠️ Tech Stack
- **Python 3.11+**
- **FAISS** (vector database)
- **sentence-transformers** (`all-MiniLM-L6-v2`)
- **Ollama** (`llama3.2:3b`)



## 📊 System Workflow


**Plain English:**  
1. **User asks a question**  
2. **Retriever** finds the most relevant chunks from the knowledge base  
3. **Generator (LLM)** uses those chunks to produce an accurate, grounded answer  
